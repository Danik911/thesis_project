# Open-Source LLM Models Configuration
# This file defines the configuration for various OSS model providers
# NO FALLBACKS: Each provider must be explicitly selected - no automatic switching

# Provider configurations for pharmaceutical test generation
providers:
  # OpenRouter - PRIMARY RECOMMENDED (Cheapest with redundancy)
  openrouter:
    endpoint: https://openrouter.ai/api/v1
    models:
      gpt-oss-120b:
        name: openai/gpt-oss-120b
        context_window: 131072
        max_output: 32768
        cost_per_m_input: 0.09
        cost_per_m_output: 0.45
        features:
          - structured_output
          - function_calling
          - json_mode
        recommended_for:
          - gamp_categorization
          - oq_generation
          - research_agent
          - sme_agent
      gpt-oss-20b:
        name: openai/gpt-oss-20b
        context_window: 131072
        max_output: 16384
        cost_per_m_input: 0.05
        cost_per_m_output: 0.25
        features:
          - structured_output
          - function_calling
        recommended_for:
          - context_provider
          - low_complexity_tasks
    performance:
      max_tps: 290
      avg_latency_ms: 500
      uptime_sla: 99.96
    authentication:
      api_key_env: OPENROUTER_API_KEY
      headers:
        HTTP-Referer: https://pharmaceutical-test-generation.com
        X-Title: GAMP-5 Test Generation System

  # Cerebras - FASTEST (3000 tokens/sec)
  cerebras:
    endpoint: https://api.cerebras.ai/v1
    models:
      gpt-oss-120b:
        name: gpt-oss-120b
        context_window: 131072
        max_output: 32768
        cost_per_m_input: 0.25
        cost_per_m_output: 0.69
        features:
          - structured_output
          - function_calling
          - ultra_low_latency
        recommended_for:
          - time_critical_operations
          - burst_traffic
          - interactive_sessions
    performance:
      max_tps: 3000
      avg_latency_ms: 300
      uptime_sla: 99.9
    authentication:
      api_key_env: CEREBRAS_API_KEY
    rate_limits:
      free_tier:
        requests_per_minute: 30
        daily_tokens: 1000000
      paid_tier:
        requests_per_minute: unlimited
        monthly_minimum: 1500

  # Together AI - BALANCED
  together:
    endpoint: https://api.together.xyz/v1
    models:
      llama-3.3-70b:
        name: meta-llama/Llama-3.3-70B-Instruct-Turbo
        context_window: 131072
        max_output: 16384
        cost_per_m_input: 0.15
        cost_per_m_output: 0.60
        features:
          - structured_output
          - function_calling
          - batch_processing
        recommended_for:
          - batch_oq_generation
          - parallel_processing
          - cost_effective_operations
    performance:
      max_tps: 170
      avg_latency_ms: 600
      uptime_sla: 99.5
    authentication:
      api_key_env: TOGETHER_API_KEY

  # Fireworks - QUICK DEPLOYMENT
  fireworks:
    endpoint: https://api.fireworks.ai/inference/v1
    models:
      llama-3.3-70b:
        name: accounts/fireworks/models/llama-v3p3-70b-instruct
        context_window: 131072
        max_output: 16384
        cost_per_m_input: 0.15
        cost_per_m_output: 0.60
        features:
          - structured_output
          - function_calling
          - serverless_scaling
        recommended_for:
          - rapid_prototyping
          - variable_workloads
    performance:
      max_tps: 260
      avg_latency_ms: 550
      uptime_sla: 99.5
    authentication:
      api_key_env: FIREWORKS_API_KEY

  # OpenAI - BASELINE COMPARISON
  openai:
    endpoint: https://api.openai.com/v1
    models:
      gpt-4o-mini:
        name: gpt-4o-mini
        context_window: 128000
        max_output: 16384
        cost_per_m_input: 10.0
        cost_per_m_output: 30.0
        features:
          - structured_output
          - function_calling
          - json_mode
          - proven_reliability
        recommended_for:
          - baseline_comparison
          - critical_operations
      o3-mini:
        name: o3-mini
        context_window: 128000
        max_output: 65536
        cost_per_m_input: 15.0
        cost_per_m_output: 60.0
        features:
          - reasoning_effort
          - complex_reasoning
        recommended_for:
          - oq_generation_baseline
    performance:
      max_tps: 100
      avg_latency_ms: 2100
      uptime_sla: 99.9
    authentication:
      api_key_env: OPENAI_API_KEY

# Testing profiles for different scenarios
testing_profiles:
  # Isolation testing - test each agent separately
  isolation:
    provider: openrouter
    model: gpt-oss-120b
    temperature: 0.1
    max_tokens: 4000
    timeout: 60
    agents:
      categorization:
        enabled: true
        success_threshold: 0.95
      oq_generator:
        enabled: true
        min_tests: 25
        max_tests: 30
      research:
        enabled: true
        fda_api_enabled: true
      sme:
        enabled: true
      context_provider:
        enabled: true
        chromadb_enabled: true

  # Integration testing - full workflow
  integration:
    provider: openrouter
    model: gpt-oss-120b
    temperature: 0.1
    max_tokens: 8000
    timeout: 300
    parallel_execution: true
    phoenix_monitoring: true
    compliance_validation: true

  # Performance testing
  performance:
    providers:
      - openrouter
      - cerebras
      - together
    metrics:
      - latency_p50
      - latency_p95
      - latency_p99
      - tokens_per_second
      - cost_per_operation
      - error_rate
    test_duration_minutes: 60
    concurrent_requests: 10

  # Compliance validation
  compliance:
    provider: openrouter
    model: gpt-oss-120b
    validation_criteria:
      gamp5_accuracy: 0.95
      alcoa_compliance: true
      cfr_part_11: true
      audit_trail_complete: true
    test_categories:
      - category_1
      - category_3
      - category_4
      - category_5

# Migration strategy
migration:
  strategy: risk_based  # Options: risk_based, parallel, gradual, immediate
  phases:
    phase_1:
      name: Low Risk Categories
      categories: [1, 3]
      provider: openrouter
      rollback_threshold: 0.05  # 5% error rate triggers rollback
    phase_2:
      name: Medium Risk Category
      categories: [4]
      provider: openrouter
      validation_required: true
      rollback_threshold: 0.02
    phase_3:
      name: High Risk Category
      categories: [5]
      provider: openai  # Stay with OpenAI until fully validated
      validation_required: true
      regulatory_approval: required

# Monitoring and alerts
monitoring:
  metrics_endpoint: http://localhost:9090/metrics
  alert_thresholds:
    error_rate: 0.01  # 1% error rate
    latency_p95: 5000  # 5 seconds
    cost_per_day: 100  # $100 per day
  logging:
    level: INFO
    include_prompts: false  # For security
    include_responses: false
    include_metrics: true
  audit_trail:
    enabled: true
    retention_days: 365  # Regulatory requirement
    encryption: AES-256
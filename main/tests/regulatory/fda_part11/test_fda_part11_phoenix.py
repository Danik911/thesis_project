"""
Enhanced Test Script for FDA Part-11 Document with Phoenix Observability

This comprehensive test demonstrates:
1. Phoenix server connection and UI accessibility  
2. FDA Part-11 document ingestion with full tracing
3. Multiple search queries with different complexity levels
4. Confidence score calculations and quality assessments
5. Complete trace visibility in Phoenix UI
6. Error handling with full diagnostics

Test Document: FDA Part-11 Electronic Records & Electronic Signatures Guidance
"""

import asyncio
import sys
import time
from pathlib import Path
from uuid import uuid4

from dotenv import load_dotenv

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Load environment variables
env_path = project_root / ".env"
load_dotenv(env_path)

from main.src.agents.parallel.context_provider import (
    ContextProviderRequest,
    create_context_provider_agent,
)
from main.src.monitoring.phoenix_config import PhoenixConfig, setup_phoenix


class FDAPartPhoenixTester:
    """Comprehensive tester for FDA Part-11 document with Phoenix observability."""

    def __init__(self):
        self.agent = None
        self.phoenix_manager = None
        self.test_document_path = project_root / "main" / "tests" / "test_data" / "FDA Part-11--Electronic-Records--Electronic-Signatures---Scope-and-Application-(PDF).md"

    async def setup_phoenix(self):
        """Initialize Phoenix observability system."""
        print("üî¨ Setting up Phoenix observability...")

        try:
            # Initialize Phoenix with project configuration
            config = PhoenixConfig(
                enable_tracing=True,
                phoenix_host="localhost",
                phoenix_port=6006,
                project_name="fda_part11_test",
                experiment_name="chromadb_integration"
            )

            self.phoenix_manager = setup_phoenix(config)

            if self.phoenix_manager and self.phoenix_manager._initialized:
                print("‚úÖ Phoenix connected successfully!")
                print("üåç Phoenix UI: http://localhost:6006")
                print("üìä Project: fda_part11_test")
                return True
            print("‚ö†Ô∏è Phoenix setup completed but may not be fully initialized")
            print("   This is normal if Phoenix dependencies are missing")
            return True  # Continue with test even if Phoenix isn't fully ready

        except Exception as e:
            print(f"‚ùå Phoenix setup failed: {e}")
            print("   Continuing test without Phoenix tracing...")
            return False

    async def setup_agent(self):
        """Initialize Context Provider Agent with Phoenix tracing."""
        print("\nü§ñ Setting up Context Provider Agent...")

        try:
            self.agent = create_context_provider_agent(
                verbose=True,
                enable_phoenix=True
            )
            print("‚úÖ Context Provider Agent initialized")
            return True

        except Exception as e:
            print(f"‚ùå Agent setup failed: {e}")
            return False

    async def test_document_ingestion(self):
        """Test FDA Part-11 document ingestion with Phoenix tracing."""
        print("\nüì• Testing FDA Part-11 Document Ingestion...")
        print(f"üìÑ Document: {self.test_document_path.name}")

        try:
            # Verify document exists
            if not self.test_document_path.exists():
                print(f"‚ùå Test document not found: {self.test_document_path}")
                return False

            # Create documents directory for ingestion
            docs_dir = project_root / "temp_test_docs"
            docs_dir.mkdir(exist_ok=True)

            # Copy FDA document to temp directory for ingestion
            import shutil
            temp_doc_path = docs_dir / "fda_part11.md"
            shutil.copy2(self.test_document_path, temp_doc_path)

            print(f"üìÅ Ingesting from: {docs_dir}")
            print("üîç This will create detailed Phoenix spans for:")
            print("   - Document processing pipeline")
            print("   - Text chunking operations")
            print("   - Embedding generation")
            print("   - ChromaDB storage operations")

            # Ingest with full tracing
            start_time = time.time()
            stats = await self.agent.ingest_documents(
                documents_path=str(docs_dir),
                collection_name="regulatory",
                force_reprocess=True
            )
            ingestion_time = time.time() - start_time

            print(f"\n‚úÖ Ingestion completed in {ingestion_time:.2f}s")
            print(f"üìä Documents processed: {stats.get('documents_processed', 'N/A')}")
            print(f"üìã Nodes created: {stats.get('nodes_created', 'N/A')}")
            print("üíæ Collection: regulatory")

            # Cleanup temp directory
            shutil.rmtree(docs_dir)

            return True

        except Exception as e:
            print(f"‚ùå Document ingestion failed: {e}")
            import traceback
            traceback.print_exc()
            return False

    async def test_search_queries(self):
        """Test multiple search queries with different complexity levels."""
        print("\nüîç Testing Search Queries with Phoenix Tracing...")

        # Define test queries with different complexity and expected behavior
        test_queries = [
            {
                "name": "Electronic Records Validation",
                "query": "What are the requirements for electronic records validation in pharmaceutical systems?",
                "expected_confidence": "high",
                "description": "Should find relevant FDA Part-11 content about electronic records"
            },
            {
                "name": "GAMP Category Relationship",
                "query": "How does 21 CFR Part 11 relate to GAMP Category 5 systems and computerized systems validation?",
                "expected_confidence": "medium-high",
                "description": "Should find some relevant content but may need inference"
            },
            {
                "name": "Electronic Signatures",
                "query": "What are the electronic signature requirements for pharmaceutical manufacturing systems?",
                "expected_confidence": "high",
                "description": "Should find specific FDA Part-11 electronic signature content"
            },
            {
                "name": "Audit Trail Requirements",
                "query": "What audit trail and data integrity requirements apply to electronic pharmaceutical records?",
                "expected_confidence": "high",
                "description": "Should find audit trail requirements in FDA Part-11"
            },
            {
                "name": "Low Relevance Query",
                "query": "What are the requirements for nuclear reactor safety protocols?",
                "expected_confidence": "low",
                "description": "Should have low confidence as not relevant to FDA Part-11"
            }
        ]

        results = []

        for i, test_query in enumerate(test_queries, 1):
            print(f"\nüìã Query {i}/5: {test_query['name']}")
            print(f"‚ùì Question: {test_query['query']}")
            print(f"üéØ Expected: {test_query['expected_confidence']} confidence")
            print(f"üìù Notes: {test_query['description']}")

            try:
                # Create request with proper structure
                request = ContextProviderRequest(
                    gamp_category="5",
                    context_depth="comprehensive",
                    document_sections=["validation_requirements", "compliance_guidelines", "electronic_records"],
                    test_strategy={
                        "type": "validation_testing",
                        "focus_areas": ["electronic_records", "signatures", "audit_trail"],
                        "compliance_level": "pharmaceutical"
                    },
                    search_scope={
                        "collections": ["regulatory", "gamp5"],
                        "max_documents": 10,
                        "relevance_threshold": 0.7
                    },
                    correlation_id=uuid4()
                )

                # Process with Phoenix tracing
                start_time = time.time()
                result = await self.agent.process_request(request)
                query_time = time.time() - start_time

                # Extract results
                confidence = result.confidence_score
                quality = result.context_quality
                doc_count = len(result.retrieved_documents)

                print(f"‚úÖ Query completed in {query_time:.2f}s")
                print(f"üî¢ Confidence: {confidence:.3f}")
                print(f"üìä Quality: {quality}")
                print(f"üìÑ Documents: {doc_count}")

                # Show top document if available
                if result.retrieved_documents:
                    top_doc = result.retrieved_documents[0]
                    print(f"üèÜ Top result: {top_doc.get('title', 'Untitled')[:60]}...")

                results.append({
                    "query": test_query["name"],
                    "confidence": confidence,
                    "quality": quality,
                    "doc_count": doc_count,
                    "time": query_time
                })

                # Small delay between queries to see traces separately
                await asyncio.sleep(1)

            except Exception as e:
                print(f"‚ùå Query failed: {e}")
                import traceback
                traceback.print_exc()
                results.append({
                    "query": test_query["name"],
                    "error": str(e)
                })

        # Summary
        print("\nüìà Query Test Summary:")
        print("=" * 50)
        for result in results:
            if "error" not in result:
                print(f"{result['query']:<25} | Conf: {result['confidence']:.3f} | Qual: {result['quality']:<6} | Docs: {result['doc_count']:>2} | Time: {result['time']:.2f}s")
            else:
                print(f"{result['query']:<25} | ERROR: {result['error']}")

        return results

    async def test_parallel_requests(self):
        """Test concurrent requests to validate Phoenix span isolation."""
        print("\nüîÑ Testing Parallel Requests...")

        requests = []
        for i in range(3):
            request = ContextProviderRequest(
                gamp_category="5",
                context_depth="focused",
                document_sections=["validation_requirements", "electronic_records"],
                test_strategy={
                    "type": "unit_testing",
                    "focus_areas": ["basic_validation"],
                    "compliance_level": "pharmaceutical"
                },
                search_scope={
                    "collections": ["regulatory"],
                    "max_documents": 5,
                    "relevance_threshold": 0.8
                },
                correlation_id=uuid4()
            )
            requests.append(request)

        try:
            print("üöÄ Launching 3 concurrent requests...")
            start_time = time.time()

            # Execute requests concurrently
            tasks = [self.agent.process_request(req) for req in requests]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            parallel_time = time.time() - start_time

            # Analyze results
            successful = [r for r in results if not isinstance(r, Exception)]
            failed = [r for r in results if isinstance(r, Exception)]

            print(f"‚úÖ Parallel execution completed in {parallel_time:.2f}s")
            print(f"üéØ Successful: {len(successful)}/3")
            print(f"‚ùå Failed: {len(failed)}/3")

            if successful:
                avg_confidence = sum(r.confidence_score for r in successful) / len(successful)
                print(f"üìä Average confidence: {avg_confidence:.3f}")

            return len(successful) == 3

        except Exception as e:
            print(f"‚ùå Parallel test failed: {e}")
            return False

    async def test_error_handling(self):
        """Test error scenarios to validate Phoenix error tracing."""
        print("\nüö® Testing Error Handling...")

        try:
            # Test with invalid collection
            print("üîç Testing invalid collection name...")

            # This should trigger an error with full Phoenix tracing
            request = ContextProviderRequest(
                gamp_category="invalid",
                context_depth="comprehensive",
                document_sections=["nonexistent_section"],
                test_strategy={
                    "type": "invalid_strategy",
                    "focus_areas": ["nonexistent"],
                    "compliance_level": "invalid"
                },
                search_scope={
                    "collections": ["nonexistent_collection"],
                    "max_documents": 5,
                    "relevance_threshold": 0.5
                },
                correlation_id=uuid4()
            )

            try:
                result = await self.agent.process_request(request)
                print("‚ö†Ô∏è Expected error but got result - check error handling")
            except Exception as e:
                print(f"‚úÖ Error properly caught and traced: {type(e).__name__}")
                print(f"üìù Error message: {str(e)[:100]}...")
                return True

        except Exception as e:
            print(f"‚ùå Error test failed: {e}")
            return False

    async def validate_phoenix_ui(self):
        """Provide instructions for Phoenix UI validation."""
        print("\nüéØ Phoenix UI Validation Instructions:")
        print("=" * 50)
        print("1. Open Phoenix UI: http://localhost:6006")
        print("2. Look for project: 'fda_part11_test'")
        print("3. Verify trace hierarchy:")
        print("   ‚îî‚îÄ‚îÄ context_provider.process_request")
        print("       ‚îú‚îÄ‚îÄ chromadb.search_documents")
        print("       ‚îÇ   ‚îú‚îÄ‚îÄ chromadb.search_collection.regulatory")
        print("       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chromadb.chunk.1")
        print("       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chromadb.chunk.2")
        print("       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...")
        print("       ‚îÇ   ‚îî‚îÄ‚îÄ search_results_summary (event)")
        print("       ‚îú‚îÄ‚îÄ context_quality_assessment (event)")
        print("       ‚îî‚îÄ‚îÄ confidence_calculation (event)")
        print("4. Check span attributes contain:")
        print("   - Query text and parameters")
        print("   - Document counts and scores")
        print("   - Processing times")
        print("   - Confidence calculation factors")
        print("5. Verify events show meaningful data")
        print("\nüîç Expected Traces:")
        print("   - Document ingestion spans")
        print("   - 5 search query spans")
        print("   - 3 parallel request spans")
        print("   - Error handling span")

    async def cleanup(self):
        """Clean up resources and flush Phoenix traces."""
        print("\nüßπ Cleaning up...")

        if self.phoenix_manager:
            try:
                print("üì§ Flushing Phoenix traces...")
                self.phoenix_manager.shutdown()
                print("‚úÖ Phoenix cleanup completed")
            except Exception as e:
                print(f"‚ö†Ô∏è Phoenix cleanup warning: {e}")

        print("‚úÖ Test cleanup completed")


async def main():
    """Main test execution function."""
    print("üè• FDA Part-11 Phoenix Observability Test")
    print("=" * 50)
    print("üìã This test will:")
    print("1. Connect to Phoenix server (start manually: docker run -d -p 6006:6006 arizephoenix/phoenix:latest)")
    print("2. Ingest FDA Part-11 document with full tracing")
    print("3. Execute multiple search queries")
    print("4. Test parallel requests")
    print("5. Validate error handling")
    print("6. Provide Phoenix UI validation instructions")
    print("\nüöÄ Starting test...")

    tester = FDAPartPhoenixTester()

    try:
        # Setup phase
        phoenix_ok = await tester.setup_phoenix()
        if not phoenix_ok:
            print("‚ö†Ô∏è Phoenix setup had issues - continuing anyway")

        agent_ok = await tester.setup_agent()
        if not agent_ok:
            print("‚ùå Agent setup failed - cannot continue")
            return

        # Test execution phase
        ingestion_ok = await tester.test_document_ingestion()
        if not ingestion_ok:
            print("‚ùå Document ingestion failed - skipping search tests")
            return

        search_results = await tester.test_search_queries()
        parallel_ok = await tester.test_parallel_requests()
        error_ok = await tester.test_error_handling()

        # Validation instructions
        await tester.validate_phoenix_ui()

        # Summary
        print("\nüéâ Test Execution Summary:")
        print("=" * 50)
        print(f"‚úÖ Phoenix Setup: {'OK' if phoenix_ok else 'Issues'}")
        print(f"‚úÖ Agent Setup: {'OK' if agent_ok else 'Failed'}")
        print(f"‚úÖ Document Ingestion: {'OK' if ingestion_ok else 'Failed'}")
        print(f"‚úÖ Search Queries: {len([r for r in search_results if 'error' not in r])}/5 successful")
        print(f"‚úÖ Parallel Requests: {'OK' if parallel_ok else 'Failed'}")
        print(f"‚úÖ Error Handling: {'OK' if error_ok else 'Failed'}")
        print("\nüåç Phoenix UI: http://localhost:6006")
        print("üìä Project: fda_part11_test")

    except Exception as e:
        print(f"‚ùå Test execution failed: {e}")
        import traceback
        traceback.print_exc()

    finally:
        await tester.cleanup()


if __name__ == "__main__":
    asyncio.run(main())

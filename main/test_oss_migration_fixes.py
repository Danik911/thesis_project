#!/usr/bin/env python3
"""
Comprehensive test suite for OSS migration fixes.

This script validates the three critical fixes implemented:
1. Configurable timeout system
2. Alternative format parsing (YAML, template-based)
3. Enhanced Phoenix instrumentation

CRITICAL: NO FALLBACKS - All failures are explicit for pharmaceutical compliance
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from pathlib import Path

# Add the main directory to path to import modules
sys.path.insert(0, str(Path(__file__).parent))

from uuid import uuid4

from src.agents.oq_generator.generator import OQTestGenerator
from src.agents.oq_generator.yaml_parser import (
    extract_yaml_from_response,
    validate_yaml_data,
)
from src.agents.parallel.sme_agent import create_sme_agent
from src.config.llm_config import LLMConfig
from src.config.timeout_config import TimeoutConfig, validate_system_timeouts
from src.core.events import AgentRequestEvent, GAMPCategory

# Configure logging for comprehensive debug output
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def check_environment():
    """Check environment setup for OSS model testing."""
    logger.info("=" * 60)
    logger.info("üîç ENVIRONMENT CHECK")
    logger.info("=" * 60)

    # Check LLM provider
    provider = os.getenv("LLM_PROVIDER", "openrouter")
    logger.info(f"LLM Provider: {provider}")

    # Check API keys
    openrouter_key = os.getenv("OPENROUTER_API_KEY")
    logger.info(f"OpenRouter API Key Present: {'‚úÖ Yes' if openrouter_key else '‚ùå No'}")

    if provider == "openrouter" and not openrouter_key:
        logger.error("‚ùå OPENROUTER_API_KEY not found in environment!")
        return False

    # Check timeout configuration
    try:
        TimeoutConfig.log_configuration(logger)

        validation_result = validate_system_timeouts()
        if validation_result:
            logger.info("‚úÖ Timeout configuration validation passed")
        else:
            logger.warning("‚ö†Ô∏è Timeout configuration has issues")

    except Exception as e:
        logger.error(f"‚ùå Timeout configuration error: {e}")
        return False

    # Check model configuration
    try:
        provider_info = LLMConfig.get_provider_info()
        logger.info(f"Model Configuration: {provider_info}")

        # Validate configuration
        is_valid, error = LLMConfig.validate_configuration()
        logger.info(f"Configuration Valid: {'‚úÖ Yes' if is_valid else '‚ùå No'}")
        if not is_valid:
            logger.error(f"Configuration Error: {error}")
            return False

    except Exception as e:
        logger.error(f"‚ùå LLM Configuration Error: {e}")
        return False

    logger.info("‚úÖ Environment check passed")
    return True


async def test_timeout_configuration():
    """Test timeout configuration and validation."""
    logger.info("=" * 60)
    logger.info("‚è∞ TIMEOUT CONFIGURATION TEST")
    logger.info("=" * 60)

    try:
        # Test timeout retrieval
        timeouts = TimeoutConfig.get_all_timeouts()
        logger.info("Current timeout configuration:")
        for service, timeout in timeouts.items():
            logger.info(f"  {service}: {timeout}s")

        # Test timeout validation
        validation = TimeoutConfig.validate_timeouts()
        logger.info("Timeout validation results:")
        logger.info(f"  Valid: {'‚úÖ Yes' if validation['valid'] else '‚ùå No'}")

        if validation["issues"]:
            logger.error("  Issues:")
            for issue in validation["issues"]:
                logger.error(f"    - {issue}")

        if validation["warnings"]:
            logger.warning("  Warnings:")
            for warning in validation["warnings"]:
                logger.warning(f"    - {warning}")

        if validation["recommendations"]:
            logger.info("  Recommendations:")
            for rec in validation["recommendations"]:
                logger.info(f"    - {rec}")

        # Test environment variable override
        test_timeout = TimeoutConfig.get_timeout("sme_agent")
        logger.info(f"SME agent timeout: {test_timeout}s")

        return validation["valid"]

    except Exception as e:
        logger.error(f"‚ùå Timeout configuration test failed: {e}")
        return False


async def test_yaml_parsing():
    """Test YAML and alternative format parsing."""
    logger.info("=" * 60)
    logger.info("üìù YAML PARSING TEST")
    logger.info("=" * 60)

    try:
        # Test YAML response parsing
        yaml_response = """
Here's your pharmaceutical test suite:

```yaml
suite_id: "OQ-SUITE-20250108-001"
gamp_category: "5"
version: "1.0"
total_test_count: 3
test_cases:
  - test_id: "OQ-001"
    test_description: "System startup and initialization validation"
    test_category: "functional"
    priority: "high"
    estimated_duration_minutes: 45
  - test_id: "OQ-002" 
    test_description: "User interface and access control validation"
    test_category: "security"
    priority: "high"
    estimated_duration_minutes: 60
  - test_id: "OQ-003"
    test_description: "Data integrity and audit trail validation"
    test_category: "data_integrity"
    priority: "high"
    estimated_duration_minutes: 90
```

This test suite meets GAMP-5 Category 5 requirements for pharmaceutical validation.
        """

        result = extract_yaml_from_response(yaml_response)
        logger.info("‚úÖ YAML parsing successful")
        logger.info(f"  Suite ID: {result.get('suite_id')}")
        logger.info(f"  GAMP Category: {result.get('gamp_category')}")
        logger.info(f"  Test Cases: {len(result.get('test_cases', []))}")

        # Validate YAML data
        validated_data = validate_yaml_data(result)
        logger.info("‚úÖ YAML validation successful")
        logger.info(f"  Validated fields: {list(validated_data.keys())}")

        return True

    except Exception as e:
        logger.error(f"‚ùå YAML parsing test failed: {e}")
        return False


async def test_llm_basic():
    """Test basic LLM functionality with timeout and instrumentation."""
    logger.info("=" * 60)
    logger.info("ü§ñ BASIC LLM TEST")
    logger.info("=" * 60)

    try:
        llm = LLMConfig.get_llm()
        logger.info(f"LLM initialized: {llm}")
        logger.info(f"  Model: {llm.model}")
        logger.info(f"  Max tokens: {llm.max_tokens}")

        # Test simple completion with timeout
        simple_prompt = "What is GAMP-5 in pharmaceutical validation? Answer in 2-3 sentences."

        logger.info("Testing basic completion...")
        start_time = datetime.now()
        response = await llm.acomplete(simple_prompt)
        duration = (datetime.now() - start_time).total_seconds()

        logger.info("‚úÖ Simple completion successful")
        logger.info(f"  Duration: {duration:.2f}s")
        logger.info(f"  Response length: {len(response.text)} chars")
        logger.info(f"  Response preview: {response.text[:150]}...")

        # Test YAML-focused generation
        yaml_prompt = """
Generate a simple pharmaceutical test case in YAML format.

Requirements:
- GAMP Category 5 system
- Include test_id, description, category, priority
- Focus on data integrity validation

Format as YAML code block.
        """

        logger.info("Testing YAML-focused generation...")
        start_time = datetime.now()
        yaml_response = await llm.acomplete(yaml_prompt)
        duration = (datetime.now() - start_time).total_seconds()

        logger.info("‚úÖ YAML generation successful")
        logger.info(f"  Duration: {duration:.2f}s")
        logger.info(f"  Response length: {len(yaml_response.text)} chars")

        # Try to parse the YAML response
        try:
            yaml_data = extract_yaml_from_response(yaml_response.text)
            logger.info("‚úÖ Generated YAML parsing successful")
        except Exception as parse_e:
            logger.warning(f"‚ö†Ô∏è Generated YAML parsing failed: {parse_e}")

        return True

    except Exception as e:
        logger.error(f"‚ùå Basic LLM test failed: {e}")
        return False


async def test_oq_generator_with_alternatives():
    """Test OQ generator with alternative format parsing."""
    logger.info("=" * 60)
    logger.info("üß™ OQ GENERATOR WITH ALTERNATIVES TEST")
    logger.info("=" * 60)

    try:
        llm = LLMConfig.get_llm()
        oq_generator = OQTestGenerator(llm=llm, verbose=True)

        logger.info("OQ Generator initialized:")
        logger.info(f"  Generation timeout: {oq_generator.generation_timeout}s")
        logger.info(f"  LLM model: {oq_generator.llm.model}")

        # Test simple OQ generation
        test_urs_content = """
        Test System Requirements:
        
        1. The system shall provide secure user authentication
        2. The system shall maintain audit trails for all data changes
        3. The system shall validate data integrity using checksums
        4. The system shall support role-based access control
        5. The system shall generate compliance reports
        
        This is a GAMP Category 5 custom application for pharmaceutical manufacturing.
        """

        logger.info("Generating OQ test suite...")
        start_time = datetime.now()

        try:
            test_suite = oq_generator.generate_oq_test_suite(
                gamp_category=GAMPCategory.CATEGORY_5,
                urs_content=test_urs_content,
                document_name="Test System URS",
                context_data={"test_context": "automated testing"}
            )

            duration = (datetime.now() - start_time).total_seconds()

            logger.info("‚úÖ OQ test suite generated successfully")
            logger.info(f"  Duration: {duration:.2f}s")
            logger.info(f"  Suite ID: {test_suite.suite_id}")
            logger.info(f"  GAMP Category: {test_suite.gamp_category}")
            logger.info(f"  Test count: {test_suite.total_test_count}")
            logger.info(f"  Test cases: {len(test_suite.test_cases)}")

            if test_suite.test_cases:
                logger.info("  First test case:")
                first_test = test_suite.test_cases[0]
                logger.info(f"    ID: {first_test.test_id}")
                logger.info(f"    Description: {first_test.test_description[:100]}...")
                logger.info(f"    Category: {first_test.test_category}")

            return True

        except Exception as gen_e:
            duration = (datetime.now() - start_time).total_seconds()
            logger.error(f"‚ùå OQ generation failed after {duration:.2f}s: {gen_e}")

            # Check if this was a timeout or parsing error
            if "timeout" in str(gen_e).lower():
                logger.error("  Issue: Timeout occurred")
            elif "parsing" in str(gen_e).lower() or "json" in str(gen_e).lower():
                logger.error("  Issue: Parsing failure (this tests our alternative formats)")

            return False

    except Exception as e:
        logger.error(f"‚ùå OQ generator test setup failed: {e}")
        return False


async def test_sme_agent_with_timeout():
    """Test SME agent with configurable timeout."""
    logger.info("=" * 60)
    logger.info("üë®‚Äçüî¨ SME AGENT WITH TIMEOUT TEST")
    logger.info("=" * 60)

    try:
        # Create SME agent
        sme_agent = create_sme_agent(
            specialty="pharmaceutical_validation",
            verbose=True
        )

        logger.info("SME agent created:")
        logger.info(f"  Specialty: {sme_agent.specialty}")
        logger.info(f"  OSS model detected: {sme_agent.is_oss_model}")
        logger.info(f"  Model: {sme_agent.llm.model}")

        # Create test request
        request = AgentRequestEvent(
            agent_type="sme",
            request_data={
                "specialty": "pharmaceutical_validation",
                "test_focus": "GAMP Category 5 OQ testing",
                "compliance_level": "high",
                "domain_knowledge": ["GAMP-5", "21 CFR Part 11", "Data Integrity"],
                "validation_focus": ["functional_testing", "data_integrity", "compliance"],
                "risk_factors": {"complexity": "high", "regulatory_impact": "critical"},
                "categorization_context": {"gamp_category": 5, "confidence_score": 0.95}
            },
            correlation_id=uuid4(),
            requesting_step="test_script",
            session_id="test_session"
        )

        logger.info("Processing SME consultation request...")
        start_time = datetime.now()

        result = await sme_agent.process_request(request)
        duration = (datetime.now() - start_time).total_seconds()

        logger.info(f"SME consultation completed in {duration:.2f}s")
        logger.info(f"  Success: {'‚úÖ Yes' if result.success else '‚ùå No'}")

        if result.success:
            recommendations = result.result_data.get("recommendations", [])
            confidence = result.result_data.get("confidence_score", 0.0)

            logger.info(f"  Recommendations: {len(recommendations)}")
            logger.info(f"  Confidence score: {confidence:.2%}")

            if recommendations:
                logger.info("  First recommendation:")
                first_rec = recommendations[0]
                logger.info(f"    Category: {first_rec.get('category', 'N/A')}")
                logger.info(f"    Priority: {first_rec.get('priority', 'N/A')}")
                logger.info(f"    Recommendation: {first_rec.get('recommendation', 'N/A')[:100]}...")

            return True
        logger.error(f"  Error: {result.error_message}")
        return False

    except Exception as e:
        logger.error(f"‚ùå SME agent test failed: {e}")
        return False


async def test_integration_workflow():
    """Test integration with timeout and alternative parsing."""
    logger.info("=" * 60)
    logger.info("üîÑ INTEGRATION WORKFLOW TEST")
    logger.info("=" * 60)

    try:
        # This is a simplified integration test
        # In a full test, we would run the unified workflow

        logger.info("Testing component integration...")

        # Test 1: Timeout consistency
        api_timeout = TimeoutConfig.get_timeout("openrouter_api")
        sme_timeout = TimeoutConfig.get_timeout("sme_agent")
        oq_timeout = TimeoutConfig.get_timeout("oq_generator")

        logger.info("Timeout hierarchy:")
        logger.info(f"  API: {api_timeout}s")
        logger.info(f"  SME: {sme_timeout}s")
        logger.info(f"  OQ: {oq_timeout}s")

        if api_timeout < sme_timeout and api_timeout < oq_timeout:
            logger.info("‚úÖ Timeout hierarchy is correct")
        else:
            logger.warning("‚ö†Ô∏è Timeout hierarchy may cause issues")

        # Test 2: Alternative parsing available
        try:
            test_yaml = "suite_id: test\ntest_cases: []"
            parsed = extract_yaml_from_response(test_yaml)
            logger.info("‚úÖ YAML parsing available")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è YAML parsing issue: {e}")

        # Test 3: LLM initialization
        llm = LLMConfig.get_llm()
        logger.info(f"‚úÖ LLM initialization successful: {llm.model}")

        logger.info("‚úÖ Integration test passed")
        return True

    except Exception as e:
        logger.error(f"‚ùå Integration test failed: {e}")
        return False


async def main():
    """Main test execution."""
    logger.info("üß™ STARTING OSS MIGRATION FIXES TEST SUITE")
    logger.info("=" * 60)
    logger.info(f"Test started at: {datetime.now().isoformat()}")
    logger.info("=" * 60)

    results = {}

    try:
        # Environment check (prerequisite)
        if not check_environment():
            logger.error("‚ùå Environment check failed - aborting tests")
            sys.exit(1)

        # Test timeout configuration
        results["timeout_config"] = await test_timeout_configuration()

        # Test YAML parsing
        results["yaml_parsing"] = await test_yaml_parsing()

        # Test basic LLM functionality
        results["llm_basic"] = await test_llm_basic()

        # Test OQ generator with alternatives
        results["oq_generator"] = await test_oq_generator_with_alternatives()

        # Test SME agent with timeout
        results["sme_agent"] = await test_sme_agent_with_timeout()

        # Test integration
        results["integration"] = await test_integration_workflow()

        # Summary
        logger.info("=" * 60)
        logger.info("üìä TEST SUMMARY")
        logger.info("=" * 60)

        success_count = sum(results.values())
        total_count = len(results)

        logger.info(f"Overall Results: {success_count}/{total_count} tests passed")
        logger.info("")

        for test_name, passed in results.items():
            status = "‚úÖ PASS" if passed else "‚ùå FAIL"
            logger.info(f"  {test_name.replace('_', ' ').title()}: {status}")

        logger.info("")

        if success_count == total_count:
            logger.info("üéâ ALL TESTS PASSED!")
            logger.info("‚úÖ OSS migration fixes are working correctly")
            logger.info("")
            logger.info("Key improvements validated:")
            logger.info("  - Configurable timeout system prevents API timeouts")
            logger.info("  - YAML and template-based parsing provides JSON alternatives")
            logger.info("  - Enhanced error handling maintains pharmaceutical compliance")
        else:
            logger.error("‚ùå SOME TESTS FAILED")
            logger.error("üîß Review the failed tests above for debugging")
            logger.error("")

            failed_tests = [name for name, passed in results.items() if not passed]
            logger.error(f"Failed tests: {', '.join(failed_tests)}")

        logger.info("=" * 60)
        logger.info(f"Test completed at: {datetime.now().isoformat()}")
        logger.info("=" * 60)

        # Exit with appropriate code
        sys.exit(0 if success_count == total_count else 1)

    except Exception as e:
        logger.error("=" * 60)
        logger.error(f"‚ùå TEST SUITE FAILED: {e}")
        logger.error("üîß Check the debug logs above for detailed error analysis")
        logger.error("=" * 60)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
